{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image # 需要在anaconda 中安装pillow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class NodeLookup(object):\n",
    "    def __init__(self):\n",
    "        leable_lookup_path = \"inception_model/imagenet_2012_challenge_label_map_proto.pbtxt\"\n",
    "        uid_lookup_path = \"inception_model/imagenet_synset_to_human_label_map.txt\"\n",
    "        self.node_lookup = self.load(leable_lookup_path,uid_lookup_path)\n",
    "#         print(\"-------->\",self.node_lookup)\n",
    "    \n",
    "    def load(self, leable_lookup_path, uid_lookup_path):\n",
    "        # 加载分类字符串，对应分类名称的文件\n",
    "        proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines();\n",
    "        uid_to_human = {}\n",
    "        # 一行一行读取数据\n",
    "        for line in proto_as_ascii_lines:\n",
    "            #去掉换行符\n",
    "            line = line.strip(\"\\n\")\n",
    "            # 按照\"\\t\"分割\n",
    "            parsed_ites = line.split(\"\\t\")\n",
    "            # 获取分类编号\n",
    "            uid = parsed_ites[0]\n",
    "            # 获取分类名称\n",
    "            human_string = parsed_ites[1]\n",
    "            # 保存编号字符串 和分类名称对应关系\n",
    "            uid_to_human[uid] = human_string\n",
    "        \n",
    "        # 加载分类字符串 对应分类编号1-1000的文件\n",
    "        proto_as_ascii = tf.gfile.GFile(leable_lookup_path).readlines();\n",
    "        node_id_to_uid = {}\n",
    "        for line in proto_as_ascii:\n",
    "            if line.startswith(\"  target_class:\"):\n",
    "                #获取分类编号 1-1000\n",
    "                target_class = int(line.split(\": \")[1])\n",
    "            if line.startswith(\"  target_class_string:\"):\n",
    "                # 获取编号字符串\n",
    "                target_class_string = line.split(\": \")[1]\n",
    "                # 保存分类编号 1-1000 和 编号字符串的映射关系\n",
    "                node_id_to_uid[target_class] = target_class_string[1:-2]\n",
    "            \n",
    "        # 建立分类编号1-1000和对应分类名称的映射关系\n",
    "        node_id_to_name = {}\n",
    "        for key , val in node_id_to_uid.items():\n",
    "            # 获取分类名称\n",
    "            name = uid_to_human[val]\n",
    "            # 建立分类编号1-1000和对应分类名称的映射关系\n",
    "            node_id_to_name[key] = name;\n",
    "            \n",
    "        return node_id_to_name;\n",
    "    \n",
    "    # 传入分类编号 1-1000 返回分类名称\n",
    "    def id_to_string(self, node_id):\n",
    "#         print(\"=======>\",node_id)\n",
    "        if node_id not in self.node_lookup:\n",
    "            return \"\"\n",
    "        return self.node_lookup[node_id];\n",
    "    \n",
    "    \n",
    "# 模型存放地址\n",
    "inception_pretrain_model_dir = \"inception_model\"\n",
    "# classify_image_graph_def.pb为google训练好的模型\n",
    "inception_graph_def_file = os.path.join(inception_pretrain_model_dir, 'classify_image_graph_def.pb')\n",
    "\n",
    "#建立一个图来存放Google训练好的模型\n",
    "with tf.gfile.FastGFile(inception_graph_def_file, 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name(\"softmax:0\")\n",
    "    # 遍历目录\n",
    "    for root,dirs,files in os.walk(\"images/\"):\n",
    "        for file in files:\n",
    "            #载入图片\n",
    "            image_data = tf.gfile.FastGFile(os.path.join(root,file),\"rb\").read()\n",
    "            predictions = sess.run(softmax_tensor,{ \"DecodeJpeg/contents:0\" : image_data }) #图片格式是jpg\n",
    "            predictions = np.squeeze(predictions) #将结果转换为一维数组\n",
    "            \n",
    "            #打印图片路径以及名称\n",
    "            image_path = os.path.join(root,file)\n",
    "            print(image_path)\n",
    "            # 显示图片\n",
    "            img = Image.open(image_path)\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            \n",
    "            # 排序\n",
    "            top_k = predictions.argsort()[-5:][::-1]\n",
    "            node_lookup = NodeLookup()\n",
    "            for node_id in top_k:\n",
    "                # 获取分类名称\n",
    "                human_string = node_lookup.id_to_string(node_id)\n",
    "                # 获取分类的可能性\n",
    "                score = predictions[node_id];\n",
    "                print(\" %s (score = %.5f )\" % (human_string,score) )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
