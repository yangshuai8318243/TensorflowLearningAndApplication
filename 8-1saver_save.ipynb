{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0905 17:32:19.242634 20276 deprecation.py:323] From <ipython-input-1-131f41d1b81a>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0905 17:32:19.249621 20276 deprecation.py:323] From E:\\TensorFlow\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0905 17:32:19.250622 20276 deprecation.py:323] From E:\\TensorFlow\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0905 17:32:19.499302 20276 deprecation.py:323] From E:\\TensorFlow\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0905 17:32:19.501804 20276 deprecation.py:323] From E:\\TensorFlow\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0905 17:32:19.555343 20276 deprecation.py:323] From E:\\TensorFlow\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0,Testing Acc0.8087\n",
      "Iter1,Testing Acc0.884\n",
      "Iter2,Testing Acc0.8938\n",
      "Iter3,Testing Acc0.9018\n",
      "Iter4,Testing Acc0.9049\n",
      "Iter5,Testing Acc0.9076\n",
      "Iter6,Testing Acc0.9097\n",
      "Iter7,Testing Acc0.9115\n",
      "Iter8,Testing Acc0.9127\n",
      "Iter9,Testing Acc0.9143\n",
      "Iter10,Testing Acc0.9163\n",
      "Iter11,Testing Acc0.9171\n",
      "Iter12,Testing Acc0.9181\n",
      "Iter13,Testing Acc0.9197\n",
      "Iter14,Testing Acc0.9187\n",
      "Iter15,Testing Acc0.9192\n",
      "Iter16,Testing Acc0.9193\n",
      "Iter17,Testing Acc0.9214\n",
      "Iter18,Testing Acc0.9209\n",
      "Iter19,Testing Acc0.9216\n",
      "Iter20,Testing Acc0.922\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf;\n",
    "import matplotlib.pylab as plt;\n",
    "\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data \n",
    "\n",
    "# 载入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)\n",
    "\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size = 100;\n",
    "import numpy as np\n",
    "import tensorflow as tf;\n",
    "import matplotlib.pylab as plt;\n",
    "\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data \n",
    "# 载入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size = 200;\n",
    "# 计算一共有多少批次\n",
    "n_batch = mnist.train.num_examples // batch_size;\n",
    "\n",
    "# 定义图片的站位数据\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# 创建神经网络\n",
    "W = tf.Variable(tf.ones([784,10]))\n",
    "b = tf.Variable(tf.ones([10]))\n",
    "\n",
    "Weights_L1 = tf.Variable(tf.random_normal([784,28]))\n",
    "# 定义偏置值也就是机器学习中的a0或者这里是输入层也可以说是x0\n",
    "biases_L1= tf.Variable(tf.zeros([1,28]))\n",
    "#计算中间层L1的数据，通过矩阵乘法计算\n",
    "Wx_plus_b_L1 = tf.matmul(x,Weights_L1) + biases_L1;\n",
    "\n",
    "L1 = tf.tanh(Wx_plus_b_L1)\n",
    "\n",
    "\n",
    "Weights_L2 = tf.Variable(tf.random_normal([28,10]))\n",
    "# 定义偏置值也就是机器学习中的a0，因为这里只有一个输出单元，所以a0值对应一个值\n",
    "biases_L2= tf.Variable(tf.zeros([1,10]))\n",
    "Wx_plus_b_L2 = tf.matmul(L1,Weights_L2) + biases_L2;\n",
    "# prediction = tf.tanh(Wx_plus_b_L2)\n",
    "# perdiction = tf.nn.softmax(Wx_plus_b_L2)\n",
    "perdiction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "# 定义二次函数 代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-perdiction))\n",
    "# 交叉熵优化\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits = perdiction))\n",
    "\n",
    "\n",
    "# 使用梯度下降\n",
    "# train_setp = tf.train.GradientDescentOptimizer(0.22).minimize(loss)\n",
    "# 1e-1标示0.1 1e就标示10负几次方\n",
    "# train_setp = tf.train.AdamOptimizer(1e-2).minimize(loss)\n",
    "train_setp = tf.train.AdadeltaOptimizer(learning_rate=1).minimize(loss)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 将返回最大的值放在一个一维张量中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(perdiction,1))\n",
    "# 测试准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size);\n",
    "            sess.run(train_setp,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\" + str(epoch) + \",Testing Acc\"+ str(acc))\n",
    "    saver.save(sess,\"net/my_net.ckpt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
